<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Lenguajes gesto-espaciales</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="375c333c-dcfb-41ef-9bdc-2cc97146e1b6" class="page sans"><header><img class="page-cover-image" src="https://www.notion.so/images/page-cover/met_georges_seurat_1884.jpg" style="object-position:center 0%"/><div class="page-header-icon page-header-icon-with-cover"><span class="icon">📏</span></div><h1 class="page-title">Lenguajes gesto-espaciales</h1><p class="page-description"></p><table class="properties"><tbody><tr class="property-row property-row-person"><th><span class="icon property-icon"><svg role="graphics-symbol" viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0" class="typesPerson"><path d="M10.9536 7.90088C12.217 7.90088 13.2559 6.79468 13.2559 5.38525C13.2559 4.01514 12.2114 2.92017 10.9536 2.92017C9.70142 2.92017 8.65137 4.02637 8.65698 5.39087C8.6626 6.79468 9.69019 7.90088 10.9536 7.90088ZM4.4231 8.03003C5.52368 8.03003 6.42212 7.05859 6.42212 5.83447C6.42212 4.63843 5.51245 3.68945 4.4231 3.68945C3.33374 3.68945 2.41846 4.64966 2.41846 5.84009C2.42407 7.05859 3.32251 8.03003 4.4231 8.03003ZM1.37964 13.168H5.49561C4.87231 12.292 5.43384 10.6074 6.78711 9.51807C6.18628 9.14746 5.37769 8.87231 4.4231 8.87231C1.95239 8.87231 0.262207 10.6917 0.262207 12.1628C0.262207 12.7974 0.548584 13.168 1.37964 13.168ZM7.50024 13.168H14.407C15.4009 13.168 15.7322 12.8423 15.7322 12.2864C15.7322 10.8489 13.8679 8.88354 10.9536 8.88354C8.04492 8.88354 6.17505 10.8489 6.17505 12.2864C6.17505 12.8423 6.50635 13.168 7.50024 13.168Z"></path></svg></span>Person</th><td><span class="user"><img src="335222723_752658819559476_2240218590879570018_n.jpg" class="icon user-icon"/>Ernesto Adrian Lozano De la Parra</span><span class="user"><img src="https://lh3.googleusercontent.com/a-/AOh14GjQN-pg1iY3O0KvehKY-afbZFGeLMolZvcZcca_pw=s100" class="icon user-icon"/>Carlos Sanchez</span></td></tr></tbody></table></header><div class="page-body"><nav id="abdd9a4a-0751-4165-81c5-cd6e552b8ea6" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#52b50edc-76a3-400a-9130-fcfcf0daa87b">Resumen</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#daf2e59c-e685-49b6-bec3-182126db9f27">Web</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#4a7893a6-e056-47f2-872d-3a5f543897ef">Repositorio (Código)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7f889ab7-0a4e-4f04-b3c0-c37cce10aabd">Instalación para CLI</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#a2590200-13b4-4cfc-ac5d-ec3b488dee34">Introducción</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#e1843a88-b5a9-4b74-b4d9-600d219cb8fd">Ecosistema</a></div></nav><h1 id="52b50edc-76a3-400a-9130-fcfcf0daa87b" class="">Resumen</h1><p id="c7c187ab-7c90-49ca-aed1-f0b6bd824f17" class="">Framework para interpretar lenguaje gesto-espaciales.</p><h2 id="daf2e59c-e685-49b6-bec3-182126db9f27" class="">Web</h2><p id="1a0ca3f1-278a-4dae-9923-a551d6b3c001" class=""><a href="https://msl.sanchezcarlosjr.com/">https://msl.sanchezcarlosjr.com/</a></p><h2 id="4a7893a6-e056-47f2-872d-3a5f543897ef" class="">Repositorio (Código)</h2><p id="906d9feb-575b-4b65-9a5a-9c6d010765fb" class=""><a href="https://github.com/sanchezcarlosjr/mexican_sign_language_toolkit">https://github.com/sanchezcarlosjr/mexican_sign_language_toolkit</a></p><h2 id="7f889ab7-0a4e-4f04-b3c0-c37cce10aabd" class="">Instalación para CLI</h2><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="d27bce9f-aa37-41fa-9dc4-699f1b2828b2" class="code"><code class="language-Bash">pip install mexican_sign_language_toolkit</code></pre><h1 id="a2590200-13b4-4cfc-ac5d-ec3b488dee34" class="">Introducción</h1><p id="7711e43a-b779-45b4-be3f-6bfa19f3fd42" class="">La interpretación del lenguaje gesto-espacial emerge como un medio significativo para facilitar una comunicación más fluida entre las personas. Además, desde una perspectiva económica, el uso de cámaras se presenta como una opción más accesible y menos costosa en comparación con otros sensores especializados. En este contexto, proponemos un marco de trabajo diseñado específicamente para interpretar gestos, expresiones faciales y otros signos no verbales. Este enfoque puede desempeñar un papel crucial en la comprensión de las necesidades, deseos y emociones de los pacientes, especialmente aquellos con demencia, quienes a menudo enfrentan desafíos significativos para comunicarse mediante el lenguaje convencional.</p><p id="3345c237-b521-49cd-bb6a-80a03b42b8e4" class="">Por ende, nuestra herramienta propuesta ofrece una alternativa valiosa y efectiva para captar y transmitir sus mensajes de manera más clara y precisa. En particular, proponemos interpretar la lengua de señas mexicana para facilitar la comunicación entre las personas sordas o con problemas auditivos y aquellas que no conocen la lengua de señas mexicana, como es el caso del trabajo de \citep{morfin_ricardo_2023}. Esta herramienta no solo eliminará barreras de comunicación, sino que también promoverá la inclusión social de las personas sordas, permitiéndoles participar de manera más activa y efectiva en la vida cotidiana y social. El objetivo principal de este escenario es describir las etapas para la interpretación de lenguaje gesto-espacial y el software asociado (<a href="https://github.com/sanchezcarlosjr/mexican_sign_language_toolkit/">https://github.com/sanchezcarlosjr/mexican_sign_language_toolkit/</a>), así como presentar como caso de estudio la lengua de señas mexicana. Esto implica el uso aprendizaje de máquina y el procesamiento de imágenes, para mejorar la precisión y velocidad de la interpretación.</p><p id="f2cef97b-f276-4f22-a46c-2b4731d5d3f9" class="">La primera etapa del proceso implica la captura de un flujo continuo de imágenes o vídeo en tiempo real. Luego, mediante Mediapipe (aunque también se pueden emplear alternativas como OpenPose o una versión de YOLO), se identificarán los puntos de referencia cruciales en las manos y el cuerpo, elementos esenciales para la interpretación de la lengua de señas. En la etapa subsiguiente, los gestos identificados se clasificarán utilizando un algoritmo basado en el método kNN (k-Nearest Neighbors o el vecino más cercano), que puede ser de fuerza bruta, K-d Tree o Ball Tree. Este algoritmo empleará una distancia métrica de Procrustes y un espacio métrico derivado del análisis de Procrustes. Este último se centra en el espacio de matrices (o formas de objetos) después de eliminar factores de translación, rotación y escala, permitiendo identificar la clase equivalente más cercana.</p><p id="e4ec63cf-f707-4ad6-940e-63adb4000839" class="">Elegimos este enfoque debido a que podemos crear un modelo eficiente con una mínima cantidad de imágenes sin entrenamiento; pero es posible clasificar mediante otros métodos, como la Máquinas de Soporte Vectorial, redes neuronales (Siamese neural network o Feature Pyramid Network con distintas arquitecturas), SIFT, SURF, ORB, Harris Corner Detector, BRISK, AZAKE, o la versión general del problema de Procustes, el Wahba’s problem, así como cambiar de dominio y verlo como un problema de clasificación de series de tiempo (<a href="https://www.aeon-toolkit.org/en/latest/examples/classification/classification.html">https://www.aeon-toolkit.org/en/latest/examples/classification/classification.html</a>). Una vez que los gestos sean reconocidos, estos se transformarán en tokens que representarán palabras en un lenguaje verbal. Posteriormente, se realizará un análisis sintáctico y semántico de las expresiones verbales del usuario. Dicho análisis puede abarcar desde la implementación de condicionales simples hasta el empleo de gramáticas complejas, inferencia de tipos o la utilización de modelos avanzados de lenguaje, como GPT4 o BERT.</p><figure id="80e14c60-9bad-47a0-9b35-447b7e0a2cec" class="image"><a href="etapas-de-lenguajes-visuales.png"><img style="width:384px" src="etapas-de-lenguajes-visuales.png"/></a></figure><p id="527ee772-3b7b-488b-a7a6-eb1ad3f86b36" class="">Estos modelos pueden aplicarse mediante técnicas como few-shot learning (<a href="https://chat.openai.com/share/05ce1523-df42-414a-89c1-7c39107e1dec">https://chat.openai.com/share/05ce1523-df42-414a-89c1-7c39107e1dec</a>), predicción de máscaras, fine-tuning o algún otro método más sofisticado. El objetivo final es transformar estos tokens en texto significativo y coherente en el idioma de destino, garantizando así una comunicación efectiva y precisa. El proceso general puede visualizarse en la Figura \ref{fig:etapas-de-lenguajes-visuales}. La expresión final no solo tiene como propósito ser traducida, sino que también cumple con una función operacional, es decir, sirve para ejecutar acciones en el sistema.</p><p id="d5ac6689-8843-4443-b225-83404e6b159a" class="">El enfoque delineado no solo es prometedor para la interpretación de la lengua de señas, sino que también ostenta el potencial de erigirse como un método universal para identificar el lenguaje gesto-espacial rico y diverso que las personas transmiten a través de sus cuerpos. Este lenguaje gesto-espacial no se limita a gestos simples como la afirmación o negación (comunicar «sí» o «no»), sino que se extiende a acciones más complejas y sutiles. Por ejemplo, puede ser útil para interpretar la revisión de una rutina de ejercicios, donde cada movimiento tiene un significado específico. Además, puede aplicarse en el estudio de la proxémica, en la identificación de posturas y gestos que denoten emociones y actitudes particulares, y también en el análisis del baile.</p><p id="dc39b628-2f98-4edb-b62e-88a5c4dd2660" class="">Conforme a \citep{sainos_vizuett_2022}, es posible categorizar nuestro enfoque, el cual está guiado por Visión por Computadora, como un método dinámico y semántico en un lenguaje objetivo. En este enfoque dinámico, cada marco de lenguaje contiene un gesto o segmento, y un conjunto de <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span> gestos conforma una palabra. Para ilustrar las etapas de nuestro método, presentamos un ejemplo utilizando la lengua de señas mexicana como caso de <a href="https://msl.sanchezcarlosjr.com/">https://msl.sanchezcarlosjr.com/</a>.</p><figure id="61de15c8-e2df-4052-9363-0c006d7f2d6b" class="image"><a href="lsm-buho.png"><img style="width:528px" src="lsm-buho.png"/></a></figure><p id="207da6cb-84e2-41a2-bee2-ad6cba737ec3" class="">En el ejemplo ilustrado se observa como un usuario al momento de realizar una seña, el sistema se encarga de reconocerla y arrojar como salida el nombre de la seña realizada. Este framework aún está en proceso de desarrollo, sin embargo, se podría incorporar en algún robot social para resolver los problemas que se presentan con otros modelos de reconocimiento de comportamientos no verbales.</p><h1 id="e1843a88-b5a9-4b74-b4d9-600d219cb8fd" class="">Ecosistema</h1><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="fde1dae4-e304-415e-a239-8f53d6b0d279" class="code"><code class="language-Mermaid">graph TD
  msl --&gt; Segmentacion
  Segmentacion --&gt; Mediapipe
  Segmentacion --&gt; OpenPose
  msl --&gt; Clasificacion
  msl --&gt; Tokenizacion
  msl --&gt; AnalisisSemantico
  Clasificacion --&gt; Procustes-y-KD-Tree
  Clasificacion --&gt; CNN-y-KD-Tree
  Tokenizacion --&gt; Regex
  Tokenizacion --&gt; AnalisisPorSerieDeTiempo
  AnalisisSemantico --&gt; Prolog-y-reglas
  AnalisisSemantico --&gt; Modelos-grandes-del-lenguaje
  </code></pre><p id="7f62eb2e-f0e6-4e9f-82ea-9d94f9bba6e7" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>